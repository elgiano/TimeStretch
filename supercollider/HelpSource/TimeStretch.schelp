class:: TimeStretch
summary:: Time Stretch
related:: TimeStretch2, Classes/FFT, Classes/IFFT, FluidTransients, FluidBufCompose
categories::  UGens>FFT

Description::
TimeStretch is the classic Cadillac of extreme time stretching algorithms - a big, hulking, and slow beauty. All calculations and audio processing are done in the language, thus calculations move at a glacial pace. For a faster version that uses the server, but doesn't sound quite as good, check out TimeStretch2.

For transient splitting and file methodology, requires the FluCoMa Fluid Decomposition Toolbox (flucoma.org).

Implements a phase randomized FFT time stretch algorithm, the NessStretch, which splits the original sound file into 9 discrete frequency bands, and uses a decreasing frame size to correspond to increasing frequency. Starting with a largest frame of 65536, the algorithm will use the following frequency/frame size breakdown:

0-86hz : 65536

86-172hz : 32768

172-344 : 16384

344-689 : 8192

689-1378 : 4096

1378-2756 : 2048

2756 - 5512 : 1024

5512-11025 : 512

11025-22050 : 256

The algorithm also correlates each grain in the FFT with the previous and next grain, and creates a custom crossfade for each overlap based on the correlations between grains.

The mergeFiles method below requires FluidBufCompose from the  FluCoMa library. This method is commented out in the distro. Files can be merged in any DAW.

classmethods::

method::stretch

Performs the stretch and places temporary files into a temporary folder.

argument::inFile

Path to the input file to be stretch. Can be a mono or stereo file.

argument::outFolder

Path to the temporary destination output folder. Will create the folder if it does not exist.


argument::durMult

	How many times longer the outFile will be than the inFile. Goes waaaaay past 11 (try 100!).

argument::chanArray

An array that indicates which channels of the inFile to process.

argument:: startFrame

Default is 0. This is the frame to start processing on. If the process has already made a number of frames, and was interrupted somehow, the process can be started in the middle by indicating here the last chunk that was successfully written to disk.

argument:: splits

By default, the algorithm will split audio data into 9 frequency "octaves", starting with the first octave below nyquist, then subsequent octaves down from there, leaving everything below the last split to the largest buffer. However, for files of transients, you may want to approach this differently. A number smaller than 9 will leave the top N octaves "normal", but will stop at the number provided. So, a 4 would have a max window size of 2048. An Array can also be provided. All values in the array need to be powers of 2, so something like [65536, 32768, 16384, 8192] will work.

argument:: chunkSize

The program will break the incoming audio into multiple output files, each with chunkSize samples. These files will go into a directory named after the name given to the outFile.

argument:: filterOrder

By default the filter will be a brickwall fft bandpass filter separating frequency bands. However, by giving filterOrder a number 128 and below, the program switches to a Linkwitz-Riley filter with the order number provided.

method::stretch2PlusChannels

Stretches a stereo+ audio file into chunked audio files in a single folder. Will open two instances of sclang in the terminal to stretch these independently.

inFile, durMult=100, chanArray, startFrame=0, splits = 9, chunkSize = 6553600|

argument::inFile

The file to stretch.

argument::durMult

See above.

argument::chanArray

See above.

argument:: startFrame

See above.

argument:: splits

See above.

argument:: chunkSize

See above.

argument:: filterOrder

See above.

method::merge

Merges the provided folder into a stereo file. Will output a wav file if possible, but a w64 if the resulting file will be too large for the wav format.

Commented out in the TimeStretchFluidExtensions.sc file. Requires the FluCoMa library for SC. Download this library, uncomment and recompile to use this.

argument:: folder

Folder containing the stretched audio segments.

argument:: numChans

Number of channels in the original audio file.

Commented out in the TimeStretchFluidExtensions.sc file. Requires the FluCoMa library for SC. Download this library, uncomment and recompile to use this.

method::transientSeparation

A convenience method for transient separation. This is a very aggressive setting, which should work for most sources. Will create a temporary directory in the folder of the inFile, and place the separated files there.

Commented out in the TimeStretchFluidExtensions.sc file. Requires the FluCoMa library for SC. Download this library, uncomment and recompile to use this.

argument::inFile

The file to separate.

method::stretchResonAndTrans

Stretches a resonance file and transients file in the tempDir created by TimeStretch.transientSeparation into separate folders in that same directory.

argument::inFile

The file that has been split by TimeStretch.transientSeparation

argument::durMult

See above.

argument::chanArray

See above.

argument:: startFrame

See above.

argument:: splits

See above for a discussion about splits. However, here you can give different numbers for the resonace and transients. So [9, 4], which is recommended, splits the resonance into 9 registers and the transients into 4 registers.

argument:: chunkSize

See above.

argument:: filterOrder

See above.


method::mergeResonAndTrans

Merges the resonance and transients folders into three files: resonance, transients, and both merged together. The outfile names will be derived from the directory names.

Commented out in the TimeStretchFluidExtensions.sc file. Requires the FluCoMa library for SC. Download this library, uncomment and recompile to use this.

argument::inFile

The file that has been split by TimeStretch.transientSeparation and stretched by TimeStretch.stretchResonAndTrans. The output file will have this same name with "_long" at the end.

argument::numChannels

Number of channels to look for and merge (ie, number of channels in the original file).

Examples::

Will start an NRT server, load the file, and execute the time stretch. Each instance of TimeStretch will run on its own server, so you can run as many simultaneously as your computer can handle.

code::

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch("Bieber", "BieberOut", 20, 100, [0,1]); //try it with Biebs

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch(Platform.resourceDir +/+ "sounds/a11wlk01.wav", Platform.recordingsDir +/+ "a11wlk01_10.wav", -1, 100, [0]);

//merge the files in the temporary folder into one file (requires FluidBufCompose from the FluCoMa library)
//the method is commented out in the source code. To uncomment, go to the TimeStretch.sc file and uncomment the *mergeFiles method
TimeStretch.mergeFiles(s, Platform.recordingsDir +/+ "a11wlk01_10_render/", 1)


//further convenience methods
//separates the sound file into resonant and transient components and places these in a temporary directory
TimeStretch.transientSeparation("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt.wav");

//stretches both the resonance and transient components separately
//for a two channel file, will open up 4 instances of the language in the terminal and stretch the channels of the two files individually
TimeStretch.stretchResonAndTrans("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt.wav", 100, [0,1], 0, [9, 4]);

//merge the resonance and transients folders into single files for each and also a single file which mixes the two
TimeStretch.mergeResonAndTrans("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt.wav")

::
