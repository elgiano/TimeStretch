class:: TimeStretch
summary:: Time Stretch
related:: TimeStretch2, Classes/FFT, Classes/IFFT, Classes/PV_Diffuser, Classes/PV_BrickWall
categories::  UGens>FFT

Description::
TimeStretch is the classic Cadillac of time stretching algorithms - a big, hulking, and slow beauty. All calculations and audio processing are done in the language, thus calculations move at a glacial pace. For a faster version that uses the server, but doesn't sound quite as good, check out TimeStretch2.

Implements a phase randomized FFT time stretch algorithm, the Ness Stretch, which splits the original sound file into 9 discrete frequency bands, and uses a decreasing frame size to correspond to increasing frequency. Starting with a largest frame of 65536, the algorithm will use the following frequency/frame size breakdown:

0-86hz : 65536

86-172hz : 32768

172-344 : 16384

344-689 : 8192

689-1378 : 4096

1378-2756 : 2048

2756 - 5512 : 1024

5512-11025 : 512

11025-22050 : 256

The algorithm also correlates each grain in the FFT with the previous and next grain, and creates a custom crossfade for each overlap based on the correlations between grains.

The mergeFiles method below requires FluidBufCompose from the  FluCoMa library. This method is commented out in the distro. Files can be merged in any DAW.

classmethods::

method::stretch

Performs the stretch and places temporary files into a temporary folder.

argument::inFile

Path to the input file to be stretch. Can be a mono or stereo file.

argument::outFolder

Path to the temporary destination output folder. Will create the folder if it does not exist.

argument::dur

The duration of the sound file to be stretched. -1 will process the entire file;

argument::durMult

	How many times longer the outFile will be than the inFile. Goes waaaaay past 11 (try 100!).

argument::chanArray

An array that indicates which channels of the inFile to process.

argument:: chunkSize

The program will break the incoming audio into multiple output files, each with chunkSize samples. These files will go into a directory named after the name given to the outFile.

argument:: startFrame

Default is 0. This is the frame to start processing on. If the process has already made a number of frames, and was interrupted somehow, the process can be started in the middle by indicating here the last chunk that was successfully written to disk.

argument:: fftType

Whether to use an (0) Real-FFT or (1) FFT. Real-FFT is default and is considerably faster than FFT.

argument:: winType

Whether to use an (0) Tan^2 window or (1) Tan window. Tan^2 (NessWindow) is default. It provides a smoother output. They both have their charms.

argument:: merge

Goes on to merge the chunks into a single file upon completion. This can also be accomplished

method::mergeFiles

argument::folder

The folder to look in to find the temporary file chunks.

argument::numChans

The number of channels to merge into the final audio file.

Examples::

Will start an NRT server, load the file, and execute the time stretch. Each instance of TimeStretch will run on its own server, so you can run as many simultaneously as your computer can handle.

code::

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch("Bieber", "BieberOut", 20, 100, [0,1]); //try it with Biebs

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch(Platform.resourceDir +/+ "sounds/a11wlk01.wav", Platform.recordingsDir +/+ "a11wlk01_10.wav", -1, 100, [0]);

//merge the files in the temporary folder into one file (requires FluidBufCompose from the FluCoMa library)
//the method is commented out in the source code. To uncomment, go to the TimeStretch.sc file and uncomment the *mergeFiles method
TimeStretch.mergeFiles(s, Platform.recordingsDir +/+ "a11wlk01_10_render/", 1)

::
