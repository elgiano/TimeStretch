class:: TimeStretch
summary:: Time Stretch
related:: TimeStretch2, Classes/FFT, Classes/IFFT, FluidTransients, FluidBufCompose
categories::  UGens>FFT

Description::
TimeStretch is the classic Cadillac of extreme time stretching algorithms - a big, hulking, and slow beauty. All calculations and audio processing are done in the language, thus calculations move at a glacial pace. For a faster version that uses the server, but doesn't sound quite as good, check out TimeStretch2.

For transient splitting and file methodology, requires the FluCoMa Fluid Decomposition Toolbox.

Implements a phase randomized FFT time stretch algorithm, the NessStretch, which splits the original sound file into 9 discrete frequency bands, and uses a decreasing frame size to correspond to increasing frequency. Starting with a largest frame of 65536, the algorithm will use the following frequency/frame size breakdown:

0-86hz : 65536

86-172hz : 32768

172-344 : 16384

344-689 : 8192

689-1378 : 4096

1378-2756 : 2048

2756 - 5512 : 1024

5512-11025 : 512

11025-22050 : 256

The algorithm also correlates each grain in the FFT with the previous and next grain, and creates a custom crossfade for each overlap based on the correlations between grains.

The mergeFiles method below requires FluidBufCompose from the  FluCoMa library. This method is commented out in the distro. Files can be merged in any DAW.

classmethods::

method::stretch

Performs the stretch and places temporary files into a temporary folder.

argument::inFile

Path to the input file to be stretch. Can be a mono or stereo file.

argument::outFolder

Path to the temporary destination output folder. Will create the folder if it does not exist.


argument::durMult

	How many times longer the outFile will be than the inFile. Goes waaaaay past 11 (try 100!).

argument::chanArray

An array that indicates which channels of the inFile to process.

argument:: startFrame

Default is 0. This is the frame to start processing on. If the process has already made a number of frames, and was interrupted somehow, the process can be started in the middle by indicating here the last chunk that was successfully written to disk.

argument:: splits

By default, the algorithm will split audio data into 9 frequency "octaves", starting with the first octave below nyquist, then subsequent octaves down from there, leaving everything below the last split to the largest buffer. However, for files of transients, you may want to approach this differently. A number smaller than 9 will leave the top N octaves "normal", but will stop at the number provided. So, a 4 would have a max window size of 2048. An Array can also be provided. All values in the array need to be powers of 2, so something like [65536, 32768, 16384, 8192] will work.

argument:: chunkSize

The program will break the incoming audio into multiple output files, each with chunkSize samples. These files will go into a directory named after the name given to the outFile.

method::transientSeparation

A convenience method for transient separation. This is a very aggressive setting, which should work for most sources.

argument::inFile

The file to separate.

argument::resFileOut

The file that will contain the resonance.

argument::transFileOut

The file that will contain the transients.

method::stretchResonAndTrans

Stretches a resonance file and transients file into separate folders.

argument::resFile

The file that contains the resonance.

argument::transFile

The file that contains the transients.

argument::durMult

See above.

argument::chanArray

See above.

argument:: startFrame

See above.

argument:: splits

See above for a discussion about splits. However, here you can give different numbers for the resonace and transients. So [9, 4], which is recommended, splits the resonance into 9 registers and the transients into 4 registers.

argument:: chunkSize

See above.

method::mergeResonAndTrans

Merges the resonance and transients folders into three files: resonance, transients, and both merged together. The outfile names will be derived from the directory names.

argument::resDir

Path to the resonance director.

argument::transDir

Path to the transients director.

argument::numChannels

Number of channels to look for and merge (ie, number of channels in the original file).

Examples::

Will start an NRT server, load the file, and execute the time stretch. Each instance of TimeStretch will run on its own server, so you can run as many simultaneously as your computer can handle.

code::

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch("Bieber", "BieberOut", 20, 100, [0,1]); //try it with Biebs

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch(Platform.resourceDir +/+ "sounds/a11wlk01.wav", Platform.recordingsDir +/+ "a11wlk01_10.wav", -1, 100, [0]);

//merge the files in the temporary folder into one file (requires FluidBufCompose from the FluCoMa library)
//the method is commented out in the source code. To uncomment, go to the TimeStretch.sc file and uncomment the *mergeFiles method
TimeStretch.mergeFiles(s, Platform.recordingsDir +/+ "a11wlk01_10_render/", 1)


//further convenience methods
//separates the sound file into resonant and transient components
TimeStretch.transientSeparation("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt.wav");

//stretches both the resonance and transient components separately
//for a two channel file, will open up 4 instances of the language in the terminal and stretch the channels of the two files individually
TimeStretch.stretchResonAndTrans("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt_resonance.wav", "/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt_transients.wav", 100, [0,1], 0, [9, 4]);

//merge the resonance and transients folders into single files for each and also a single file which mixes the two
TimeStretch.mergeResonAndTrans("/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt_resonance/","/Volumes/T2/USmileTransientsExcerpt/u-smile_excerpt_transients/")

::
